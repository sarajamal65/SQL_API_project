{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ed21fd9",
   "metadata": {},
   "source": [
    "# How to download flights csv file from transtats website"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac59b93e",
   "metadata": {},
   "source": [
    "**In this notebook, we will**\n",
    "1. Download a csv file for each of your chosen year(s) and month(s)\n",
    "2. Prepare the data for further processing\n",
    "3. Push the prepared data to a table in the database\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b777e805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2 # needed to get database exception errors when uploading dataframe\n",
    "import requests # package for getting data from the web\n",
    "from zipfile import * # package for unzipping zip files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f576d796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the get_engine function from our sql_functions.\n",
    "from sql_functions import get_engine #adjust this as necessary to match your sql_functions.py connection methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc483e3e",
   "metadata": {},
   "source": [
    "# 1. Download csv file with flight data for your specific year/month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3c3fe3",
   "metadata": {},
   "source": [
    "In the following, you are going to download a csv file containing flight data from [this website](https://transtats.bts.gov).    \n",
    "You can specify, which data you want to download. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09d000b",
   "metadata": {},
   "source": [
    "Choose a month/year that you want to explore further.\n",
    "With the following functions, you will download a csv file on public flight data from [this website](https://transtats.bts.gov) containing data of your chosen month/year.    \n",
    "The file will be stored in a data folder.\n",
    "Check out the url from which we download the data(https://transtats.bts.gov/PREZIP). Can we download data in this way from every source? What do you think?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a61deca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: data/: File exists\n"
     ]
    }
   ],
   "source": [
    "# Specifies path for saving file\n",
    "path ='data/' \n",
    "# Create the data folder\n",
    "!mkdir {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dff7a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get specified csv file from the website https://transtats.bts.gov\n",
    "\n",
    "def download_data(year, month):\n",
    "    # Get the file from the website https://transtats.bts.gov\n",
    "    zip_file = f'On_Time_Reporting_Carrier_On_Time_Performance_1987_present_{year}_{month}.zip'\n",
    "    url = (f'https://transtats.bts.gov/PREZIP/{zip_file}')\n",
    "    # Download the database\n",
    "    r = requests.get(f'{url}', verify=False)\n",
    "    # Save database to local file storage\n",
    "    with open(path+zip_file, 'wb') as f:\n",
    "        f.write(r.content)\n",
    "        print(f'--> zip_file with name: {zip_file} downloaded succesfully.' )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1588f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to extract the csv files inside the zip files\n",
    "\n",
    "def extract_zip(year, month):\n",
    "    # Get the file from the website https://transtats.bts.gov\n",
    "    zip_file = f'On_Time_Reporting_Carrier_On_Time_Performance_1987_present_{year}_{month}.zip'\n",
    "    with ZipFile(path+zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(path)\n",
    "        csv_file =  zip_ref.namelist()[0]\n",
    "        print(f'--> zip_file was succesfully extracted to: {csv_file}.' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3c824f",
   "metadata": {},
   "source": [
    "Don't worry - the following download of the data you chose may take some time ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8738fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/nf_sql/lib/python3.9/site-packages/urllib3/connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'transtats.bts.gov'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> zip_file with name: On_Time_Reporting_Carrier_On_Time_Performance_1987_present_2019_7.zip downloaded succesfully.\n",
      "--> zip_file was succesfully extracted to: On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2019_7.csv.\n"
     ]
    }
   ],
   "source": [
    "years_list = [2019] # list of years you want to look at (can of course also be a single year)\n",
    "months_list = [7] # list of months you want to look at (can of course also be a single month)\n",
    "\n",
    "# download flights data as zipfile(s)\n",
    "# we use a nested loop to specify the years and months to define the range of the data we would like to have \n",
    "for year in years_list:\n",
    "    for month in months_list:\n",
    "        download_data(year, month)\n",
    "        extract_zip(year, month)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5956edf",
   "metadata": {},
   "source": [
    "Now it is time to load the csv files into dataframes. You can create your own function equivalent to the functions above. But you need to decide whether...\n",
    "\n",
    "- Do you need one dataframe for every month?\n",
    "- Would you like to proceed with only one dataframe containing all the data you downloaded?\n",
    "- One dataframe for every year?\n",
    "\n",
    "There are certain things to consider before.\n",
    "- changing column names\n",
    "- dealing with missing data\n",
    "- changing datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b82b9ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(659029, 110)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>FlightDate</th>\n",
       "      <th>Reporting_Airline</th>\n",
       "      <th>DOT_ID_Reporting_Airline</th>\n",
       "      <th>IATA_CODE_Reporting_Airline</th>\n",
       "      <th>Tail_Number</th>\n",
       "      <th>...</th>\n",
       "      <th>Div4TailNum</th>\n",
       "      <th>Div5Airport</th>\n",
       "      <th>Div5AirportID</th>\n",
       "      <th>Div5AirportSeqID</th>\n",
       "      <th>Div5WheelsOn</th>\n",
       "      <th>Div5TotalGTime</th>\n",
       "      <th>Div5LongestGTime</th>\n",
       "      <th>Div5WheelsOff</th>\n",
       "      <th>Div5TailNum</th>\n",
       "      <th>Unnamed: 109</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-07-24</td>\n",
       "      <td>G4</td>\n",
       "      <td>20368</td>\n",
       "      <td>G4</td>\n",
       "      <td>249NV</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-07-29</td>\n",
       "      <td>G4</td>\n",
       "      <td>20368</td>\n",
       "      <td>G4</td>\n",
       "      <td>319NV</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2019-07-07</td>\n",
       "      <td>G4</td>\n",
       "      <td>20368</td>\n",
       "      <td>G4</td>\n",
       "      <td>324NV</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2019-07-07</td>\n",
       "      <td>G4</td>\n",
       "      <td>20368</td>\n",
       "      <td>G4</td>\n",
       "      <td>325NV</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-07-08</td>\n",
       "      <td>G4</td>\n",
       "      <td>20368</td>\n",
       "      <td>G4</td>\n",
       "      <td>261NV</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Quarter  Month  DayofMonth  DayOfWeek  FlightDate Reporting_Airline  \\\n",
       "0  2019        3      7          24          3  2019-07-24                G4   \n",
       "1  2019        3      7          29          1  2019-07-29                G4   \n",
       "2  2019        3      7           7          7  2019-07-07                G4   \n",
       "3  2019        3      7           7          7  2019-07-07                G4   \n",
       "4  2019        3      7           8          1  2019-07-08                G4   \n",
       "\n",
       "   DOT_ID_Reporting_Airline IATA_CODE_Reporting_Airline Tail_Number  ...  \\\n",
       "0                     20368                          G4       249NV  ...   \n",
       "1                     20368                          G4       319NV  ...   \n",
       "2                     20368                          G4       324NV  ...   \n",
       "3                     20368                          G4       325NV  ...   \n",
       "4                     20368                          G4       261NV  ...   \n",
       "\n",
       "   Div4TailNum  Div5Airport  Div5AirportID  Div5AirportSeqID Div5WheelsOn  \\\n",
       "0          NaN          NaN            NaN               NaN          NaN   \n",
       "1          NaN          NaN            NaN               NaN          NaN   \n",
       "2          NaN          NaN            NaN               NaN          NaN   \n",
       "3          NaN          NaN            NaN               NaN          NaN   \n",
       "4          NaN          NaN            NaN               NaN          NaN   \n",
       "\n",
       "  Div5TotalGTime Div5LongestGTime  Div5WheelsOff Div5TailNum  Unnamed: 109  \n",
       "0            NaN              NaN            NaN         NaN           NaN  \n",
       "1            NaN              NaN            NaN         NaN           NaN  \n",
       "2            NaN              NaN            NaN         NaN           NaN  \n",
       "3            NaN              NaN            NaN         NaN           NaN  \n",
       "4            NaN              NaN            NaN         NaN           NaN  \n",
       "\n",
       "[5 rows x 110 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define the name of the csv file you want to read in\n",
    "csv_file = 'On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2019_7.csv'\n",
    "\n",
    "# Read in your data\n",
    "df = pd.read_csv(path+csv_file, low_memory = False)\n",
    "display(df.shape)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fdf703",
   "metadata": {},
   "source": [
    "# 2. Prepare the csv file for further processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f4e575",
   "metadata": {},
   "source": [
    "In the next step, we clean and prepare our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441c52f5",
   "metadata": {},
   "source": [
    "a) Since the dataset consists of a lot of columns, we we define which ones to keep.  \n",
    "(Same as known from our SQL exercises on flights data.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63c35afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns from downloaded file that are to be kept\n",
    "\n",
    "columns_to_keep = [\n",
    "                'FlightDate',\n",
    "                'DepTime',\n",
    "                'CRSDepTime',\n",
    "                'DepDelay',\n",
    "                'ArrTime',\n",
    "                'CRSArrTime',\n",
    "                'ArrDelay',\n",
    "                'Reporting_Airline',\n",
    "                'Tail_Number',\n",
    "                'Flight_Number_Reporting_Airline',\n",
    "                'Origin',\n",
    "                'Dest',\n",
    "                'AirTime',\n",
    "                'ActualElapsedTime',\n",
    "                'Distance',\n",
    "                'Cancelled',\n",
    "                'Diverted'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37ad1b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = get_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c182c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('flight_date',),\n",
       " ('dep_time',),\n",
       " ('sched_dep_time',),\n",
       " ('dep_delay',),\n",
       " ('arr_time',),\n",
       " ('sched_arr_time',),\n",
       " ('arr_delay',),\n",
       " ('airline',),\n",
       " ('tail_number',),\n",
       " ('flight_number',),\n",
       " ('origin',),\n",
       " ('dest',),\n",
       " ('air_time',),\n",
       " ('actual_elapsed_time',),\n",
       " ('distance',),\n",
       " ('cancelled',),\n",
       " ('diverted',)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The columns in the database have different naming as in the source csv files. Lets get the names from the database\n",
    "\n",
    "schema = 'cgn_analytics_22_3' # UPDATE 'TABLE_SCHEMA' based on schema used in class \n",
    "engine = get_engine() # assign engine to be able to query against the database\n",
    "\n",
    "table_name_sql = f'''SELECT COLUMN_NAME \n",
    "                    FROM INFORMATION_SCHEMA.COLUMNS \n",
    "                    WHERE TABLE_NAME = 'flights'\n",
    "                    AND TABLE_SCHEMA ='{schema}'\n",
    "                    ORDER BY ordinal_position'''\n",
    "c_names = engine.execute(table_name_sql).fetchall()\n",
    "c_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7369d37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['flight_date',\n",
       " 'dep_time',\n",
       " 'sched_dep_time',\n",
       " 'dep_delay',\n",
       " 'arr_time',\n",
       " 'sched_arr_time',\n",
       " 'arr_delay',\n",
       " 'airline',\n",
       " 'tail_number',\n",
       " 'flight_number',\n",
       " 'origin',\n",
       " 'dest',\n",
       " 'air_time',\n",
       " 'actual_elapsed_time',\n",
       " 'distance',\n",
       " 'cancelled',\n",
       " 'diverted']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can clean up the results into a clean list\n",
    "new_column_names=[]\n",
    "for name in c_names:\n",
    "    new_column_names.append(name[0])\n",
    "new_column_names        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09331857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"new_column_names_alternate = ['flight_date', 'dep_time', 'sched_dep_time', 'dep_delay', 'arr_time', 'sched_arr_time', \\n                'arr_delay', 'airline', 'tail_number', 'flight_number', 'origin', 'dest', 'air_time', 'actual_elapsed_time', 'distance', 'cancelled', 'diverted' ]\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just in case the above fails here are the results\n",
    "'''new_column_names_alternate = ['flight_date', 'dep_time', 'sched_dep_time', 'dep_delay', 'arr_time', 'sched_arr_time', \n",
    "                'arr_delay', 'airline', 'tail_number', 'flight_number', 'origin', 'dest', 'air_time', 'actual_elapsed_time', 'distance', 'cancelled', 'diverted' ]'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d59e6ec",
   "metadata": {},
   "source": [
    "b) With the next function, we make our csv file ready to be uploaded to SQL.  \n",
    "We only keep to above specified columns and convert the datatypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c725271",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_airline_df(df):\n",
    "    '''\n",
    "    Transforms a df made from BTS csv file into a df that is ready to be uploaded to SQL\n",
    "    Set rows=0 for no filtering\n",
    "    '''\n",
    "\n",
    "    # Build dataframe including only the columns you want to keep\n",
    "    df_airline = df.loc[:,columns_to_keep]\n",
    "     \n",
    "    # Clean data types and NULLs\n",
    "    df_airline['FlightDate']= pd.to_datetime(df_airline['FlightDate'], yearfirst=True)\n",
    "    df_airline['CRSArrTime']= pd.to_numeric(df_airline['CRSArrTime'], downcast='integer', errors='coerce')\n",
    "    df_airline['Cancelled']= pd.to_numeric(df_airline['Cancelled'], downcast='integer')\n",
    "    df_airline['Diverted']= pd.to_numeric(df_airline['Diverted'], downcast='integer')\n",
    "    df_airline['ActualElapsedTime']= pd.to_numeric(df_airline['ActualElapsedTime'], downcast='integer', errors='coerce')\n",
    "    \n",
    "    # Rename columns\n",
    "    df_airline.columns = new_column_names\n",
    "    \n",
    "    return df_airline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a7b4082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flight_date</th>\n",
       "      <th>dep_time</th>\n",
       "      <th>sched_dep_time</th>\n",
       "      <th>dep_delay</th>\n",
       "      <th>arr_time</th>\n",
       "      <th>sched_arr_time</th>\n",
       "      <th>arr_delay</th>\n",
       "      <th>airline</th>\n",
       "      <th>tail_number</th>\n",
       "      <th>flight_number</th>\n",
       "      <th>origin</th>\n",
       "      <th>dest</th>\n",
       "      <th>air_time</th>\n",
       "      <th>actual_elapsed_time</th>\n",
       "      <th>distance</th>\n",
       "      <th>cancelled</th>\n",
       "      <th>diverted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-07-24</td>\n",
       "      <td>1533.0</td>\n",
       "      <td>1511</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1659.0</td>\n",
       "      <td>1644</td>\n",
       "      <td>15.0</td>\n",
       "      <td>G4</td>\n",
       "      <td>249NV</td>\n",
       "      <td>1246</td>\n",
       "      <td>PIE</td>\n",
       "      <td>AVL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>519.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-07-29</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>2002</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2344.0</td>\n",
       "      <td>2335</td>\n",
       "      <td>9.0</td>\n",
       "      <td>G4</td>\n",
       "      <td>319NV</td>\n",
       "      <td>2106</td>\n",
       "      <td>AUS</td>\n",
       "      <td>SFB</td>\n",
       "      <td>132.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>994.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-07-07</td>\n",
       "      <td>1118.0</td>\n",
       "      <td>1118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1139.0</td>\n",
       "      <td>1144</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>G4</td>\n",
       "      <td>324NV</td>\n",
       "      <td>112</td>\n",
       "      <td>GRI</td>\n",
       "      <td>LAS</td>\n",
       "      <td>128.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>971.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-07-07</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>1643</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1922.0</td>\n",
       "      <td>1827</td>\n",
       "      <td>55.0</td>\n",
       "      <td>G4</td>\n",
       "      <td>325NV</td>\n",
       "      <td>802</td>\n",
       "      <td>AUS</td>\n",
       "      <td>MEM</td>\n",
       "      <td>95.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>559.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-07-08</td>\n",
       "      <td>905.0</td>\n",
       "      <td>858</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1119.0</td>\n",
       "      <td>1107</td>\n",
       "      <td>12.0</td>\n",
       "      <td>G4</td>\n",
       "      <td>261NV</td>\n",
       "      <td>833</td>\n",
       "      <td>IND</td>\n",
       "      <td>PIE</td>\n",
       "      <td>118.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>840.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  flight_date  dep_time  sched_dep_time  dep_delay  arr_time  sched_arr_time  \\\n",
       "0  2019-07-24    1533.0            1511       22.0    1659.0            1644   \n",
       "1  2019-07-29    2010.0            2002        8.0    2344.0            2335   \n",
       "2  2019-07-07    1118.0            1118        0.0    1139.0            1144   \n",
       "3  2019-07-07    1726.0            1643       43.0    1922.0            1827   \n",
       "4  2019-07-08     905.0             858        7.0    1119.0            1107   \n",
       "\n",
       "   arr_delay airline tail_number  flight_number origin dest  air_time  \\\n",
       "0       15.0      G4       249NV           1246    PIE  AVL      66.0   \n",
       "1        9.0      G4       319NV           2106    AUS  SFB     132.0   \n",
       "2       -5.0      G4       324NV            112    GRI  LAS     128.0   \n",
       "3       55.0      G4       325NV            802    AUS  MEM      95.0   \n",
       "4       12.0      G4       261NV            833    IND  PIE     118.0   \n",
       "\n",
       "   actual_elapsed_time  distance  cancelled  diverted  \n",
       "0                 86.0     519.0          0         0  \n",
       "1                154.0     994.0          0         0  \n",
       "2                141.0     971.0          0         0  \n",
       "3                116.0     559.0          0         0  \n",
       "4                134.0     840.0          0         0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call function and check resulting dataframe\n",
    "df_clean = clean_airline_df(df)\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b742a452",
   "metadata": {},
   "source": [
    "If you decide to only look at specific airports, it is a good decision to filter for them in advance.  \n",
    "This function does the filtering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a42676a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the airports you are interested in and put them as a list in the function.\n",
    "def select_airport(df, airports):\n",
    "    ''' Helper function for filtering the airline dataframe for a subset of airports'''\n",
    "    df_out = df.loc[(df.origin.isin(airports)) | (df.dest.isin(airports))]\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "339add17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 87781 entries, 8 to 658995\n",
      "Data columns (total 17 columns):\n",
      " #   Column               Non-Null Count  Dtype         \n",
      "---  ------               --------------  -----         \n",
      " 0   flight_date          87781 non-null  datetime64[ns]\n",
      " 1   dep_time             86620 non-null  float64       \n",
      " 2   sched_dep_time       87781 non-null  int64         \n",
      " 3   dep_delay            86620 non-null  float64       \n",
      " 4   arr_time             86574 non-null  float64       \n",
      " 5   sched_arr_time       87781 non-null  int16         \n",
      " 6   arr_delay            86302 non-null  float64       \n",
      " 7   airline              87781 non-null  object        \n",
      " 8   tail_number          87677 non-null  object        \n",
      " 9   flight_number        87781 non-null  int64         \n",
      " 10  origin               87781 non-null  object        \n",
      " 11  dest                 87781 non-null  object        \n",
      " 12  air_time             86302 non-null  float64       \n",
      " 13  actual_elapsed_time  86302 non-null  float64       \n",
      " 14  distance             87781 non-null  float64       \n",
      " 15  cancelled            87781 non-null  int8          \n",
      " 16  diverted             87781 non-null  int8          \n",
      "dtypes: datetime64[ns](1), float64(7), int16(1), int64(2), int8(2), object(4)\n",
      "memory usage: 10.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Execute function, filtering for New York area airports\n",
    "airports=['LIT', 'XNA', 'MSY', 'ATL','BHM', 'JAN']\n",
    "if len(airports) > 0:\n",
    "    df_selected_airports = select_airport(df_clean, airports)\n",
    "else:\n",
    "    df_selected_airports = df_clean\n",
    "    \n",
    "df_selected_airports.head()\n",
    "df_selected_airports.shape\n",
    "df_selected_airports.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635eaad3",
   "metadata": {},
   "source": [
    "# 3. Push the prepared data to a table in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "252af774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engine(postgresql://user:***@host/database)\n"
     ]
    }
   ],
   "source": [
    "# create an engine\n",
    "engine = get_engine()\n",
    "print(engine)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a45a3970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The flights_jsmn table was imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# Specify which table within your database you want to push your data to. Give your table an unambiguous name.\n",
    "# Example: flights_sp for Sina's flights table, flights_groupname or similar\n",
    "table_name = 'flights_jsmn'\n",
    "# If the specified table doesn't exist yet, it will be created\n",
    "# With 'replace', your data will be replaced if the table already exists.\n",
    "# This may take some time ...\n",
    "\n",
    "# Write records stored in a dataframe to SQL database\n",
    "if engine!=None:\n",
    "    try:\n",
    "        df_selected_airports.to_sql(name=table_name, # Name of SQL table\n",
    "                        con=engine, # Engine or connection\n",
    "                        if_exists='replace', # Drop the table before inserting new values \n",
    "                        schema=schema, # Use schmea that was defined earlier\n",
    "                        index=False, # Write DataFrame index as a column\n",
    "                        chunksize=5000, # Specify the number of rows in each batch to be written at a time\n",
    "                        method='multi') # Pass multiple values in a single INSERT clause\n",
    "        print(f\"The {table_name} table was imported successfully.\")\n",
    "    # Error handling\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        engine = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4bcdcb6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just to be sure: Check if the number of rows match\n",
    "table_name_sql = f'''SELECT count(*) \n",
    "                    FROM {schema}.{table_name}\n",
    "                    '''\n",
    "engine.execute(table_name_sql).fetchall()[0][0] == df_selected_airports.shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nf_sql",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a81d278bed5b5b59425dcb5a82ce505657686243c184b4a6b67e69d01c4d432e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
